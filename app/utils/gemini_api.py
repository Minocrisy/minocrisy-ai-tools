"""
Minocrisy AI Tools - Google Gemini API Utilities
Utilities for interacting with the Google Gemini API.
"""
import google.generativeai as genai
from flask import current_app
from app.utils.secrets import get_gemini_api_key

# Simple in-memory storage for conversation history
_conversation_memory = {}

def initialize_gemini():
    """Initialize the Gemini API with the API key."""
    api_key = get_gemini_api_key()
    if not api_key:
        current_app.logger.error("Gemini API key not configured")
        return False
    
    genai.configure(api_key=api_key)
    return True

def generate_image(prompt, model="gemini-2.0-flash", size="1024x1024", quality="standard", n=1):
    """
    Generate an image using Google's Gemini Flash 2.0 model.
    
    Args:
        prompt: The text prompt to generate an image from.
        model: The model to use (default: "gemini-2.0-flash").
               Options: "gemini-2.0-flash", "gemini-2.0-flash-001"
        size: The size of the image (default: "1024x1024").
        quality: The quality of the image (default: "standard").
        n: The number of images to generate (default: 1).
        
    Returns:
        A list of image URLs, or None if an error occurred.
    """
    if not initialize_gemini():
        return None
    
    try:
        # Configure image generation parameters
        generation_config = {
            "temperature": 0.4,
            "top_p": 1,
            "top_k": 32,
            "max_output_tokens": 2048,
        }
        
        # Create a model instance
        model_instance = genai.GenerativeModel(model_name=model, generation_config=generation_config)
        
        # Generate image
        response = model_instance.generate_content(
            [prompt],
            generation_config={"output_modality": "image"}
        )
        
        # Extract image URLs from response
        if response and hasattr(response, 'candidates') and len(response.candidates) > 0:
            urls = []
            for candidate in response.candidates[:n]:
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    for part in candidate.content.parts:
                        if hasattr(part, 'image_url'):
                            urls.append(part.image_url)
            return urls
        
        current_app.logger.error("No images generated by Gemini API")
        return None
    
    except Exception as e:
        current_app.logger.error(f"Error calling Gemini API: {e}")
        return None

def chat_completion(messages, model="gemini-2.0-flash", temperature=0.7, max_tokens=1000):
    """
    Generate a chat completion using the Gemini API.
    
    Args:
        messages: A list of message objects with 'role' and 'content' keys.
        model: The model to use (default: "gemini-2.0-flash").
        temperature: Controls randomness (0-1).
        max_tokens: Maximum number of tokens to generate.
        
    Returns:
        The generated response as a string, or None if an error occurred.
    """
    if not initialize_gemini():
        return None
    
    try:
        # Configure generation parameters
        generation_config = {
            "temperature": temperature,
            "top_p": 1,
            "top_k": 32,
            "max_output_tokens": max_tokens,
        }
        
        # Create a model instance
        model_instance = genai.GenerativeModel(model_name=model, generation_config=generation_config)
        
        # Convert messages to Gemini format
        gemini_messages = []
        for msg in messages:
            role = "user" if msg["role"] == "user" else "model"
            gemini_messages.append({"role": role, "content": msg["content"]})
        
        # Generate response
        chat = model_instance.start_chat(history=gemini_messages)
        response = chat.send_message(gemini_messages[-1]["content"])
        
        if response and hasattr(response, 'text'):
            return response.text
        
        current_app.logger.error("No text generated by Gemini API")
        return None
    
    except Exception as e:
        current_app.logger.error(f"Error calling Gemini API: {e}")
        return None

def get_conversation_memory(session_id):
    """Get conversation memory for a session."""
    if session_id not in _conversation_memory:
        _conversation_memory[session_id] = []
    return _conversation_memory[session_id]

def add_to_conversation_memory(session_id, role, content):
    """Add a message to conversation memory."""
    if session_id not in _conversation_memory:
        _conversation_memory[session_id] = []
    
    _conversation_memory[session_id].append({
        "role": role,
        "content": content
    })
    
    # Limit memory size to prevent excessive token usage
    if len(_conversation_memory[session_id]) > 20:
        _conversation_memory[session_id] = _conversation_memory[session_id][-20:]
